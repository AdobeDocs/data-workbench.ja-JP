---
description: データセットには、Data Workbench サーバーによって読み込まれて処理されたデータが格納されます。
title: データセットの構築について
uuid: 540d159d-3f72-49dd-9929-107f1fc62b2b
exl-id: 111e98b5-d899-4f79-90ce-70f520d527d6
source-git-commit: b1dda69a606a16dccca30d2a74c7e63dbd27936c
workflow-type: tm+mt
source-wordcount: '937'
ht-degree: 88%

---

# データセットの構築について{#understanding-dataset-construction}

{{eol}}

データセットには、Data Workbench サーバーによって読み込まれて処理されたデータが格納されます。

データセット構築プロセスでは、Data Workbench サーバー（InsightServer64.exe）側でデータの読み込みと処理が行われます。

>[!NOTE]
>
>データセットからのデータを処理して提供する Data WorkbenchAdobeは、データ処理ユニットまたは DPU と呼ばれます。 また、処理サーバーやクエリーサーバーと呼ばれることもあります。Data Workbench クライアントと [!DNL Report] クライアントは、DPU との間で直接情報をやり取りします。

データセットの構築中、Data Workbench サーバーは、ソースのログからデータを読み取って特定のフィールドのデータに変換し、さらに、変換後のフィールドから拡張ディメンションを派生させます。構築プロセスは 2 つの段階で構成されます。 *ログ処理* および *変換*. データセットの構築後、この拡張ディメンションを使用して、特定の分析用途に派生した指標やディメンションを作成することができます。

データセットの構築は製造工程に例えることができます。データセットを構築するためのデータ（原料）を選び、変換（加工ステップ）を定義して、そのデータに含まれている情報を加工し、拡張ディメンション（製品）を作成します。

<!--
c_log_proc.xml
-->

ログにはフィルターが適用されて、変換段階に渡すデータのフィールドが特定されます。ログ処理段階の最後に、データは追跡 ID でグループ化され（つまり、同じ追跡 ID を持つすべてのログエントリがまとめられ）、時系列順に並べ替えられます。ログ処理段階で処理済みのデータにアクセスして分析に使用することはできません。

## ログソースの指定 {#section-75279dd6a7304d469735562796741d0f}

ログソースは、データセット構築用の元データを含むファイルです。各データレコードが 1 件のトランザクションレコードまたは 1 回のイベントの発生を表していることから、ログソース内のデータは「イベントデータ」と呼ばれます。また、各レコード（ログエントリ）には「追跡 ID」と呼ばれる値が格納されます。

>[!NOTE]
>
>ログソースを選択する場合は、各ログエントリに、データをグループ化する最上位レベルを表すエンティティの追跡 ID が含まれていることを確認します。 例えば、Web サイトトへのアクセスデータを扱う場合、通常、「訪問者」がそのようなエンティティに該当します。訪問者にはそれぞれ一意の追跡 ID があって、特定のサイト訪問者に関するすべてのデータを 1 つにまとめることができます。不明な点はアドビにお問い合わせください。

ログソースのイベントデータは、 [!DNL Sensors] または、アーカイブされたデータソースから Insight サーバーによって抽出されます。 HTTP サーバーおよびアプリケーションサーバーから Sensor によって収集されたイベントデータは Insight サーバーに送信され、そこで、高圧縮ログ ( [!DNL .vsl]) ファイルに書き込むことができます。 フラットなテキストファイル、XML ファイルまたは ODBC データソースに存在するイベントデータを読み取る Insight サーバーは、こうした様々な形式のファイルから決まった一連のログフィールドを抽出するよう設定されたデコーダーの役割を担います。

## 変換の定義 {#section-55a8cdb47379484081e53087f074778d}

変換とは一連の命令であり、イベントデータ内の情報を抽出したり加工したりする目的で独自に定義することができます。独自に定義した個々の変換が各イベントデータレコード（ログエントリ）に適用されて、既存のログフィールドが更新されるか、新しいフィールドが生成されます。ログ処理時にデータセットから抽出するログエントリは、この変換の結果とログエントリ条件とを組み合わせて判断されます。

一部のタイプの変換については、データセット構築のログ処理段階で使用することができません。

## ログのフィルタリング {#section-6172ca0fb0eb4177925151bb49fdbc02}

データセットには、変換の結果として得られるデータをフィルタリングするための、様々なパラメーターが存在します。フィルタリングは、後続の処理ステップで使用するログエントリを絞り込む手段です。例えば、サーバーの応答ステータスや IP アドレス、ユーザーエージェント情報、時間範囲に基づいて、フィルターを定義することができます。この [!DNL Log Entry Condition] は、カスタマイズ可能なフィルタリングテストです。 これによって各ログエントリのフィールドから特定の条件を探し、データセット構築プロセスにおいて、そのエントリの処理を続けるべきかどうかを判断します。その条件をログエントリが満たしていなかった場合、そのエントリは構築プロセスから除外されます。

## 変換対象フィールドの識別 {#section-eef98ca723e54547b887aefdf0514c47}

特定のフィールドのデータをログ処理段階から変換段階に渡して、さらなる処理を適用するためには、ログ処理時にそのフィールドを識別する必要があります。この点に関して、対象のフィールドがログソースから得られたものか、ログ処理段階でデータに適用されたデータ変換の結果として作成されたものかは関係ありません。

<!--
c_transformation.xml
-->

データセット構築の変換段階では、グループ化と順序付けの済んだデータ（ログ処理段階からの出力）に対して処理が適用されます。別途データ変換が実行され、分析に使用する拡張データディメンションが作成されます。変換段階においてアクセスできるデータの統計サンプルは、その完了に近づくにつれて大きくなります。

## 変換の定義 {#section-001b3fd4c1dd4dd38a5536872bc9de68}

データセット構築プロセスの変換段階で使用される変換を独自に定義することによって、拡張ディメンションの作成を省力化できます。個々の変換が、ログ処理から渡される各イベントデータレコード（ログエントリ）に適用されます。

## ログのフィルタリング {#section-3fed0a00ca344a719b5e8db363f64f06}

ログ処理から渡される各ログエントリのフィールドでは、変換時に [!DNL Log Entry Condition] を適用することによって特定の条件を調べることができます。その条件をログエントリが満たしていなかった場合、そのエントリは構築プロセスから除外されます。

## 拡張ディメンションの定義 {#section-25efafd0bfc84c86b9717d453a88c91b}

拡張ディメンションは、データセット構築プロセスの最終的な成果物です。データ内のログフィールド間の関係が、拡張ディメンションによって表されます。拡張ディメンションを使用したビジュアライゼーションや拡張指標を作成することや、分析によって、自分の仕事に関連した業務や問題を把握することができます。
